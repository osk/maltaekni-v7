{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Máltækni, verkefni 7\n",
    "\n",
    "## 1) Levenshtein–fall (2 stig)\n",
    "\n",
    "Í þessum hluta verkefnisins eigið þið að útfæra ykkar eigið Levenshtein–fall. Þið megið nota hvað sem er ykkur til innblásturs (það er m.a. sauðakóði á Wikipedia) en þið þurfið að útfæra fallið sjálf (með öðrum orðum ekki skila inn import levenshtein-distance). Athugið að þið megið nota pakka á borð við numpy eða hvað sem ykkur dettur í hug ef það gagnast ykkur. Látið fallið reikna út Levenshtein–fjarlægðina á nokkrum strengjum að eigin vali."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Útfærum bæði endurkvæma útgáfu og útgáfu sem notar Wagner–Fischer reikniritið í `levenshtein.py` og með prófum í `tests/test_levenshtein.py`.\n",
    "\n",
    "Sem hliðarspor þá setti ég upp með `poetry` og prófaði `coverage` pakkann til að fylgjast code coverage, sem við náum í 100%! (Er að nota `tokenizer` úr verkefni 3.)\n",
    "\n",
    "\n",
    "```bash\n",
    "> poetry run coverage run -m pytest\n",
    "=================== test session starts ===================\n",
    "tests/test_dictionary.py .....                       [ 22%]\n",
    "tests/test_levenshtein.py ...                        [ 36%]\n",
    "tests/test_tokenizer.py ..............               [100%]\n",
    "=================== 22 passed in 0.02s ====================\n",
    "\n",
    "> poetry run coverage report -m    \n",
    "Name                        Stmts   Miss  Cover   Missing\n",
    "---------------------------------------------------------\n",
    "dictionary.py                  18      0   100%\n",
    "levenshtein.py                 25      0   100%\n",
    "tests/__init__.py               0      0   100%\n",
    "tests/test_dictionary.py       18      0   100%\n",
    "tests/test_levenshtein.py      10      0   100%\n",
    "tests/test_tokenizer.py        35      0   100%\n",
    "tokenizer.py                   37      0   100%\n",
    "---------------------------------------------------------\n",
    "TOTAL                         143      0   100%\n",
    "```\n",
    "\n",
    "Endurkvæma útgáfan virkar fínt á stutta strengi en um leið og þeir verða átta stafir eða lengri tekur það **langan** tíma að reikna niðurstöðu. Wagner–Fischer er mun fljótari að reikna lengri strengi, þó það taki smá stund."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def ld_recusive(a, b):\n",
    "    \"\"\"\n",
    "    Calculate levenshtein distance between two strings via rescursion\n",
    "    \"\"\"\n",
    "    # we only allow strings\n",
    "    if not isinstance(a, str) or not isinstance(b, str):\n",
    "        return 0\n",
    "\n",
    "    # |a| = 0 => |b|\n",
    "    if len(a) == 0:\n",
    "        return len(b)\n",
    "\n",
    "    # |b| = 0 => |a|\n",
    "    if len(b) == 0:\n",
    "        return len(a)\n",
    "\n",
    "    if a[0] == b[0]:\n",
    "        return ld_recusive(a[1:], b[1:])\n",
    "\n",
    "    return 1 + min(\n",
    "        [\n",
    "            ld_recusive(a[1:], b),\n",
    "            ld_recusive(a, b[1:]),\n",
    "            ld_recusive(a[1:], b[1:]),\n",
    "        ]\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from levenshtein import ld_recusive, ld_wf\n",
    "\n",
    "ld_recusive(\"hello\", \"world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def ld_wf(s, t):\n",
    "    \"\"\"\n",
    "    Calculate levenshtein distance between two strings via Wagner–Fischer\n",
    "    https://en.wikipedia.org/wiki/Wagner%E2%80%93Fischer_algorithm\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str) or not isinstance(t, str):\n",
    "        return 0\n",
    "\n",
    "    m = len(s) + 1\n",
    "    n = len(t) + 1\n",
    "    d = [[0 for _ in range(n)] for _ in range(m)]\n",
    "\n",
    "    for i in range(1, m):\n",
    "        d[i][0] = i\n",
    "\n",
    "    for j in range(1, n):\n",
    "        d[0][j] = j\n",
    "\n",
    "    for j in range(1, n):\n",
    "        for i in range(1, m):\n",
    "            substitutionCost = 0 if s[i - 1] == t[j - 1] else 1\n",
    "\n",
    "            d[i][j] = min(\n",
    "                [d[i - 1][j] + 1, d[i][j - 1] + 1, d[i - 1][j - 1] + substitutionCost]\n",
    "            )\n",
    "\n",
    "    return d[m - 1][n - 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld_wf(\"hello world this is a test string\", \"and now for something completely different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Orðabókaruppfletting (2 stig)\n",
    "\n",
    "Í þessum hluta verkefnisins eigið þið að útfæra orðabókaruppflettingu sem greinir rangt skrifuð orð út frá því hvort þau eru til í orðaforðanum eða ekki. Þetta má útfæra á ýmsa vegu, verið endilega frumleg með gagnastrúktúra. Það sem við viljum fá út úr þessu er einfaldlega fall eða klasi sem kannar hvort eitthvað ákveðið orð sé til í fyrirfram skilgreindum orðaforða. Til þess að skilgreina orðaforðann skuluð þið nota gagnasafnið sem þið söfnuðuð sjálf (með öðrum orðum ætti forritið ykkar að líta svo á að allar stakar orðmyndir sem finnast í gögnunum ykkar séu réttar en allar orðmyndir sem finnast ekki í gögnunum ykkar séu rangar). Sýnið niðurstöðurnar þegar forritið fær orð sem inntak sem er ekki í orðaforðanum (þ.e.a.s. sýnið þegar forritið finnur villu) og þegar forritið fær orð sem inntak sem er til í orðaforðanum (þ.e.a.s. sýnið þegar forritið finnur rétt skrifað orð). Það má nota hvaða forritasafn sem þið viljið í þetta (bara ekki skila import dictionary-lookup)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Byrjum með einfalda orðabók sem tekur við strengjum og segir til um hvort strengurinn sé til eða ekki (nota enga skemmtilega gagnastrúktúra hér, bara einfalda lista).\n",
    "\n",
    "Notum sönglagatexta og tokenizer úr verkefni 3.\n",
    "\n",
    "Búum líka til hjálparfall sem tekur við setningu, tókar og skilar hvort orð séu í orðabókinni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import WORD, tokenize\n",
    "\n",
    "with open(\"./data/songlog.txt\", \"rb\") as input_file:\n",
    "    songlog = input_file.read().decode(\"utf8\")\n",
    "    tokens = [token[0] for token in tokenize(songlog) if token[1] == WORD]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from tokenizer import tokenize, WORD\n",
    "\n",
    "\n",
    "class Dictionary:\n",
    "    def __init__(self, values):\n",
    "        if not isinstance(values, list):\n",
    "            raise \"values must be list\"\n",
    "\n",
    "        clean = []\n",
    "        for value in values:\n",
    "            if not isinstance(value, str):\n",
    "                raise \"non string value in values\"\n",
    "            if value not in clean:\n",
    "                clean.append(value.lower())\n",
    "\n",
    "        self.values = clean\n",
    "\n",
    "    def has(self, value):\n",
    "        return value.lower() in self.values\n",
    "\n",
    "    def sentence(self, s):\n",
    "        tokens = [token[0] for token in tokenize(s) if token[1] == WORD]\n",
    "\n",
    "        result = [(word, self.has(word)) for word in tokens]\n",
    "\n",
    "        return result\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = Dictionary(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict.has('sólin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict.has('bull')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ástin', True),\n",
       " ('er', True),\n",
       " ('foo', False),\n",
       " ('veruleikinn', True),\n",
       " ('er', True),\n",
       " ('bar', True),\n",
       " ('með', True),\n",
       " ('þér', True),\n",
       " ('og', True),\n",
       " ('baz', False)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hjálparfall sem tókar og athugar hvert orð\n",
    "dict.sentence('Ástin er foo, veruleikinn er bar með þér og baz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Transformer <mask> sem leiðréttingartól (2 stig)\n",
    "\n",
    "Í þessum hluta verkefnisins eigið þið að kanna hvort þið getið beitt MLM líkani (t.d. BERT eða félögum hans – verið alveg viss um að hann tali rétta tungumálið hins vegar, það er ekki hentugt að beita IceBERT á texta á ensku) til þess að finna villur og leiðrétta þær. Það skal gera á eftirfarandi hátt:\n",
    "\n",
    "1) Sendið setningu sem inniheldur rangt skrifað orð inn í orðabókaruppflettinguna (þetta má t.a.m. gera með því að tóka setninguna og senda hvern tóka fyrir sig inn í forritið). Þar með ættuð þið að hafa fundið villuna.\n",
    "\n",
    "2) Skiptið rangt skrifaða orðinu út fyrir <mask> í setningunni. Sendið setninguna síðan í gegnum Transformer líkanið og fáið út þau 10 orð sem líkanið telur líklegast að eigi að standa í stað <mask>.\n",
    "\n",
    "3) Beitið Levenshtein–fallinu ykkar á þessi 10 orð sem líkanið lagði til (með öðrum orðum: hver er Levenshtein–fjarlægðin á milli upphaflega villuorðsins sem þið földuð og þessara orða). Hvert þeirra hefur lægstu fjarlægðina? Er það gild leiðrétting á orðinu sem þið skrifuðuð rangt til að byrja með (eða ef mörg orð koma til greina, er það meðal þeirra sem hafa lægstu Levenshtein–fjarlægðina)? Athugið að það er ekkert víst að þið fáið rétta niðurstöðu. Ef rétta orðið finnst alls ekki, prófið aðra (einfaldari) setningu ykkur til gamans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notum IceBERT og búum til leiðréttingarfall fyrir íslensku!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForMaskedLM, RobertaTokenizer, pipeline\n",
    "\n",
    "MODEL_NAME = \"mideind/IceBERT\"\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = RobertaForMaskedLM.from_pretrained(MODEL_NAME)\n",
    "pipe = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DISTANCE = 2\n",
    "\n",
    "\n",
    "def pick_possible(word, possibles):\n",
    "    \"\"\"Fyrir gefið `word` velur það sem er líkast og innan hámarks LD\"\"\"\n",
    "    ranked_by_distance = sorted(\n",
    "        [\n",
    "            {\n",
    "                \"word\": possible[\"token_str\"].strip(),\n",
    "                \"distance\": ld_wf(word, possible[\"token_str\"].strip()),\n",
    "            }\n",
    "            for possible in possibles\n",
    "        ],\n",
    "        key=lambda i: i[\"distance\"],\n",
    "    )\n",
    "\n",
    "    if ranked_by_distance[0][\"distance\"] <= MAX_DISTANCE:\n",
    "        return ranked_by_distance[0][\"word\"]\n",
    "\n",
    "    return word\n",
    "\n",
    "\n",
    "def correct(sentence, dictionary, pipeline):\n",
    "    \"\"\"Athugar orð í gefinni setningu og reynir að leiðrétta.\"\"\"\n",
    "    checked = dict.sentence(sentence)\n",
    "\n",
    "    # Ef engar villur, skilum setningu\n",
    "    # Hér erum við búin að strípa út allt sem er ekki WORD en þetta er einföldun\n",
    "    if all([c[1] for c in checked]):\n",
    "        return \"\".join([s[0] for s in sentence])\n",
    "\n",
    "    corrected = []\n",
    "    index = -1\n",
    "\n",
    "    # Förum gegnum öll orð sem eru ekki í orðabók og reynum hvert\n",
    "    for c in checked:\n",
    "        index = index + 1\n",
    "        if c[1]:\n",
    "            corrected.append(c[0])\n",
    "            continue\n",
    "\n",
    "        # Útbúum maskaða setningu úr því sem komið er og því sem fylgir\n",
    "        masked = \" \".join(\n",
    "            corrected\n",
    "            + [\"<mask>\"]\n",
    "            + [c[0] for c in checked[index + 1 : index + len(checked)]]\n",
    "        )\n",
    "        possibles = pipe(masked)\n",
    "\n",
    "        # Veljum besta orð úr möguleikum eða í versta fallið vitlausa orðið\n",
    "        corrected.append(pick_possible(c[0], possibles))\n",
    "\n",
    "    return \" \".join(corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Halló! Hvað segið þið gott?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skilar réttri setningu óbreyttri\n",
    "correct(\"Halló! Hvað segið þið gott?\", dict, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Í dag er góður dagur'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# náum að laga innsláttarvillu, en strípum öll greinamerki\n",
    "correct(\"Í dag, er góðr... dagur!\", dict, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'byggjum okkur hús'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# og aðra\n",
    "correct(\"Biggjum okkur hús\", dict, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hvað er í matinn'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# og nær að leiðrétta tvær villur!\n",
    "correct(\"hva er í matin\", dict, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hún er ég'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setningar sem eru óljósar er erfitt að leiðrétta\n",
    "# lækkaði mörkin töluvert niður (í 2) eftir að hafa fengi mun meira af false-positives\n",
    "correct(\"hún er fe\", dict, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lykillinn að húsinu er týndur frá því í gær þegar við fórum út í bíl með hundinn'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# og bara verður betra með lengri setningum\n",
    "correct(\"likillinn að húsinu er týndur fra því í gaer þegar við forum út í biil með hundin\", dict, pipe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ae2e14ec575573b8be072e4f3a87b89fe042cbcbb9ac3447dde126ec4009b8f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
